{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bicycle_modeling_gy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyw2OKfspB6ZZo2X397Xo1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berrygayo/DeeplearningStudy/blob/main/bicycle_modeling_gy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCEOpGxXtNDG"
      },
      "source": [
        "### 가옹 체크할 것 \n",
        "# 사용 변수가 적은것 같음 ... > 전체변수 한번 더 정리해서 넣으면 점수 높아질 것 같음 \n",
        "# 각 모델별 params가 뜻하는게 무엇인지 정리 \n",
        "\n",
        "# 따라서 앞으로 해볼만한 연구는 \n",
        "# 1. 최대한 많은 변수 넣어서 동일한 코드에 적용해보기. \n",
        "# 2.현재 진행했던 모델은 3개인데 더 많은 모델로 분석 돌려보고, 결과를 보고 상위 n 개 앙상블 모델 다시 진행 \n",
        "# 3. 최종 코드 class 로 정리 및 .py 파일로 저장(?)\n",
        "\n",
        "\n",
        "import numpy as numpy\n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# lodading data\n",
        "train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/딥러닝스터디-빅분기/자전거수요예측/bicycle_trainingset_211118.csv')\n",
        "\n",
        "train_name = ['year','rainyday', 'temp_scaled', 'h_0',\n",
        "              'h_1', 'h_2', 'h_3', 'h_4', 'h_5', 'h_6', 'h_7', 'h_8', 'h_9', 'h_10',\n",
        "              'h_11', 'h_12', 'h_13', 'h_14', 'h_15', 'h_16', 'h_17', 'h_18', 'h_19',\n",
        "              'h_20', 'h_21', 'h_22', 'h_23','hw_0', 'hw_1', 'hw_2', 'hw_3', 'hw_4', 'hw_5',\n",
        "              'hw_6', 'hw_7', 'hw_8', 'hw_9', 'hw_10', 'hw_11', 'hw_12', 'hw_13',\n",
        "              'hw_14', 'hw_15', 'hw_16', 'hw_17', 'hw_18', 'hw_19', 'hw_20', 'hw_21',\n",
        "              'hw_22', 'hw_23', 'count']\n",
        "\n",
        "X_train_name = ['year','rainyday', 'temp_scaled', 'h_0',\n",
        "                'h_1', 'h_2', 'h_3', 'h_4', 'h_5', 'h_6', 'h_7', 'h_8', 'h_9', 'h_10',\n",
        "                'h_11', 'h_12', 'h_13', 'h_14', 'h_15', 'h_16', 'h_17', 'h_18', 'h_19',\n",
        "                'h_20', 'h_21', 'h_22', 'h_23','hw_0', 'hw_1', 'hw_2', 'hw_3', 'hw_4', 'hw_5',\n",
        "                'hw_6', 'hw_7', 'hw_8', 'hw_9', 'hw_10', 'hw_11', 'hw_12', 'hw_13',\n",
        "                'hw_14', 'hw_15', 'hw_16', 'hw_17', 'hw_18', 'hw_19', 'hw_20', 'hw_21',\n",
        "                'hw_22', 'hw_23']\n",
        "\n",
        "Y_train_name = 'count'\n",
        "\n",
        "train = train.loc[:, train_name]\n",
        "X = train.loc[:, X_train_name]\n",
        "target = train[Y_train_name]\n",
        "target_log = np.log1p(target)\n",
        "\n",
        "# data split \n",
        "print(\">>> 현재 y값은 로그값이 취한 값으로 실측값을 확인하고 싶을땐 exponential 필요합니다. \") \n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, target_log, test_size = 0.25, random_state = 123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eUCkcZSSZW4"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbUkCk68tw7G"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBKX2e8yx7If"
      },
      "source": [
        "\n",
        "### 가옹 체크할 것 \n",
        "# training set 어떻게 구성되어있는지 ? train, val, test 구분 필요 \n",
        "# 데이터셋 확인 전체적으로, 사용 변수 정리 \n",
        "\n",
        "# RMSLE Scorer\n",
        "def rmsle(y,y_,convertExp=True):\n",
        "    # 지수화 필요하다면\n",
        "    if convertExp:\n",
        "        print(\"지수화를 실행합니다.\")\n",
        "        y = np.exp(y),\n",
        "        y_ = np.exp(y_)\n",
        "    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n",
        "    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n",
        "    calc = (log1 - log2) ** 2\n",
        "    return np.sqrt(np.mean(calc))\n",
        "\n",
        "\n",
        "###################################################      Modeling      ################################################\n",
        "### Score train, valid ###\n",
        "### 파라미터 튜닝 전 ###\n",
        "### RF 0.275, 0.415 ###\n",
        "### LR 0.391, 0.397 ###\n",
        "### GB 0.318, 0.381 ###\n",
        "############################\n",
        "\n",
        "# Randomforest Model\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
        "\n",
        "RF_reg= RandomForestRegressor(random_state=0)\n",
        "RF_reg.fit(X_train, y_train)\n",
        "\n",
        "preds_train = RF_reg.predict(X_train)\n",
        "preds_valid = RF_reg.predict(X_valid)\n",
        "print(\"Randomforest Train Score is: \",rmsle(np.exp(y_train), np.exp(preds_train),False) )\n",
        "print(\"Randomforest Valid Score is: \",rmsle(np.exp(y_valid), np.exp(preds_valid),False) )\n",
        "# 지수화 상태로 넣고싶지 않다면\n",
        "#print(\"Randomforest Train Score is: \",rmsle(y_train, preds_train) )\n",
        "#print(\"Randomforest Valid Score is: \",rmsle(y_valid, preds_valid) )\n",
        "\n",
        "# Linear Regression Model \n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics \n",
        "\n",
        "LM_reg = LinearRegression()\n",
        "LM_reg.fit(X_train, y_train) \n",
        "\n",
        "preds_train = LM_reg.predict(X_train)\n",
        "preds_valid = LM_reg.predict(X_valid)\n",
        "print(\"Linear Regression Train Score is: \",rmsle(np.exp(y_train), np.exp(preds_train),False) )\n",
        "print(\"Linear Regression Valid Score is: \",rmsle(np.exp(y_valid), np.exp(preds_valid),False) )\n",
        "\n",
        "# Gradient Boost Model\n",
        "from sklearn.ensemble import GradientBoostingRegressor \n",
        "gb_reg = GradientBoostingRegressor()\n",
        "gb_reg.fit(X_train, y_train)\n",
        "\n",
        "preds_train = gb_reg.predict(X_train)\n",
        "preds_valid = gb_reg.predict(X_valid)\n",
        "print(\"Gradient Boost Train Score is: \",rmsle(np.exp(y_train), np.exp(preds_train),False) )\n",
        "print(\"Gradient Boost Valid Score is: \",rmsle(np.exp(y_valid), np.exp(preds_valid),False) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UXlB68bx7Mk"
      },
      "source": [
        "###################################################      param tuning     ################################################\n",
        "%%time \n",
        "# lr은 param tuning 없이 바로 진행\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html# \n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from sklearn.pipeline import Pipeline, make_pipeline \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "pipe_rf = Pipeline([('model',RandomForestRegressor() )])\n",
        "pipe_gb = Pipeline([('model',GradientBoostingRegressor() )])\n",
        "\n",
        "param_grid_rf = [{\n",
        "                  'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)], # 트리 수 \n",
        "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)], # 트리의 최대 깊이\n",
        "                  'min_samples_split': [2, 5, 10], # 내부 노드 분할하는데 필요한 최소샘플 수 \n",
        "                  'min_samples_leaf': [1, 2, 4], # 리프 노드에 있어야하는 최소 샘플 수 \n",
        "                }]\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = RF_reg, param_distributions = param_grid_rf, n_iter = 100, cv = 5, verbose = 2, random_state = 0, n_jobs= -1)\n",
        "rf_random.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OikANjv-eqm2"
      },
      "source": [
        "# rf \n",
        "print(\"RamdomForest best param is : \", rf_random.best_params_)\n",
        "print(\"RamdomForest best score is : \",rf_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDrX7MxJHkm2"
      },
      "source": [
        "param_grid_gb = [{'max_depth':[3,5],\n",
        "             'learning_rate':[0.1, 0.01, 0.3],\n",
        "                'alpha':[0.5, 0.1, 0.9]}]\n",
        "gb_random = GridSearchCV(estimator = gb_reg, param_grid = param_grid_gb, cv=10, n_jobs=-1, verbose=2)\n",
        "gb_random.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyTHI2CYx7Ou"
      },
      "source": [
        "# gb \n",
        "print(\"GradientBoosting best param is : \", gb_random.best_params_)\n",
        "print(\"GradientBoosting best score is : \", gb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n324JjCwuf0c"
      },
      "source": [
        "###################################################      Modeling 2     ################################################\n",
        "### Score train, valid ###\n",
        "### 파라미터 튜닝 후 ###\n",
        "### RF 0.317, 0.391 ###\n",
        "### LR 0.391, 0.397 ###\n",
        "### GB 0.354, 0.376 ###\n",
        "############################\n",
        "\n",
        "# Randomforest Model\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
        "\n",
        "RF_reg= RandomForestRegressor(n_estimators= 911, min_samples_split= 10, min_samples_leaf= 2, max_depth= 80)\n",
        "RF_reg.fit(X_train, y_train)\n",
        "\n",
        "preds_train = RF_reg.predict(X_train)\n",
        "preds_valid = RF_reg.predict(X_valid)\n",
        "print(\"Randomforest Train Score is: \",rmsle(np.exp(y_train), np.exp(preds_train),False) )\n",
        "print(\"Randomforest Valid Score is: \",rmsle(np.exp(y_valid), np.exp(preds_valid),False) )\n",
        "# 지수화 상태로 넣고싶지 않다면\n",
        "#print(\"Randomforest Train Score is: \",rmsle(y_train, preds_train) )\n",
        "#print(\"Randomforest Valid Score is: \",rmsle(y_valid, preds_valid) )\n",
        "\n",
        "# Linear Regression Model \n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics \n",
        "\n",
        "LM_reg = LinearRegression()\n",
        "LM_reg.fit(X_train, y_train) \n",
        "\n",
        "preds_train = LM_reg.predict(X_train)\n",
        "preds_valid = LM_reg.predict(X_valid)\n",
        "print(\"Linear Regression Train Score is: \",rmsle(np.exp(y_train), np.exp(preds_train),False) )\n",
        "print(\"Linear Regression Valid Score is: \",rmsle(np.exp(y_valid), np.exp(preds_valid),False) )\n",
        "\n",
        "# Gradient Boost Model\n",
        "from sklearn.ensemble import GradientBoostingRegressor \n",
        "gb_reg = GradientBoostingRegressor(alpha= 0.1, learning_rate= 0.3, max_depth= 3)\n",
        "gb_reg.fit(X_train, y_train)\n",
        "\n",
        "preds_train = gb_reg.predict(X_train)\n",
        "preds_valid = gb_reg.predict(X_valid)\n",
        "print(\"Gradient Boost Train Score is: \",rmsle(np.exp(y_train), np.exp(preds_train),False) )\n",
        "print(\"Gradient Boost Valid Score is: \",rmsle(np.exp(y_valid), np.exp(preds_valid),False) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXS7y3el5hKA"
      },
      "source": [
        "# 지수화 상태로 넣고싶지 않다면\n",
        "print(\"Randomforest Train Score is: \",rmsle(y_train, preds_train) )\n",
        "print(\"Randomforest Valid Score is: \",rmsle(y_valid, preds_valid) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcSqYBny4Pee"
      },
      "source": [
        "LM_reg.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj1HnzvO4O-E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD03l-0buf2l"
      },
      "source": [
        "###################################################      Voting Regressor     ################################################\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "model_vote = VotingRegressor([ ('LinearRegression',LM_reg),('Randomforest',RF_reg),('GradientBoosting',gb_reg) ])\n",
        "model_vote.fit(X_train, y_train)\n",
        "\n",
        "preds_train = model_vote.predict(X_train)\n",
        "preds_valid = model_vote.predict(X_valid)\n",
        "print(\"Voting Regressor Train Score is: \",rmsle(np.exp(y_train), np.exp(preds_train),False) )\n",
        "print(\"Voting Regressor Boost Valid Score is: \",rmsle(np.exp(y_valid), np.exp(preds_valid),False) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ3WP01Nuf4o"
      },
      "source": [
        "###################################################      model save    ################################################\n",
        "import pickle \n",
        "from joblib import dump, load\n",
        "\n",
        "dump(model_vote, '/content/drive/MyDrive/Bigdata_study/딥러닝스터디-빅분기/자전거수요예측/voting_rf_lr_gb.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO96r4uruf66"
      },
      "source": [
        "###################################################      model loading    ################################################\n",
        "clf_from_joblib = load('/content/drive/MyDrive/Bigdata_study/딥러닝스터디-빅분기/자전거수요예측/voting_rf_lr_gb.pkl') \n",
        "clf_from_joblib.predict(X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pZma7VU8BZh"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2M3DECt8GJQ"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}