{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH4v2bDi8k9g"
   },
   "source": [
    "# 공유 자전거 수요 예측 (11.30 고지혜)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiDstRzn8k9i"
   },
   "source": [
    "### 라이브러리 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aCEOpGxXtNDG"
   },
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# 시각화 라이브러리\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# 모델링을 위한 sklearn 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "#from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# score를 내줄 함수\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# 모델링에 활용한 패키지\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fcBY_dBK8k9l"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "train = pd.read_csv('C:/Users/Berry/Documents/GitHub/DeeplearningStudy/고지혜/prepro_train.csv')\n",
    "test = pd.read_csv('C:/Users/Berry/Documents/GitHub/DeeplearningStudy/고지혜/prepro_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxE9nmop8k9m"
   },
   "source": [
    "### 베이스라인 모델링\n",
    "특정 기법을 통해 학습 및 평가했을 때, 기존의 모델보다 좋아졌는지 판단하기 위해 기준으로 삼을 베이스라인 모델을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6X9xu3__8k9n"
   },
   "outputs": [],
   "source": [
    "# 전처리한 변수들이 있는데 이 중에서 분석에 활용한 변수를 선택해줍시다.\n",
    "# 기존 데이터에 덮어쓰기보단 train_copy라는 예비 데이터프레임을 생성하여 저장해줍시다.\n",
    "train_copy = train\n",
    "\n",
    "col = ['holiday', 'workingday', 'atemp', 'humidity', 'windspeed',\n",
    "       'rainyday', 'ideal', 'sticky', 'peak', 'temp(difference)',\n",
    "       'discomfort_index', 'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_5',\n",
    "       'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12',\n",
    "       'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18',\n",
    "       'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'hw_0', 'hw_1',\n",
    "       'hw_2', 'hw_3', 'hw_5', 'hw_6', 'hw_7', 'hw_8', 'hw_9', 'hw_10',\n",
    "       'hw_11', 'hw_12', 'hw_13', 'hw_14', 'hw_15', 'hw_16', 'hw_17', 'hw_18',\n",
    "       'hw_19', 'hw_20', 'hw_21', 'hw_22', 'hw_23', 'year_2012', 'dayofweek_0',\n",
    "       'dayofweek_2', 'dayofweek_3', 'dayofweek_4', 'dayofweek_5',\n",
    "       'dayofweek_6', 'season_2', 'season_3', 'season_4', 'month_2', 'month_3',\n",
    "       'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9',\n",
    "       'month_10', 'month_11', 'month_12']\n",
    "\n",
    "# count를 제외한 변수들을 담은 데이터프레임.\n",
    "X_features = train[col]\n",
    "X_test = test[col]\n",
    "\n",
    "# 타겟 변수는 log 처리를 해준 count 변수\n",
    "target = train['log_count']\n",
    "\n",
    "# 데이터를 나눠줌\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X_features, target, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AMJ7-cKT8k9n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'holiday', 'workingday', 'atemp', 'humidity', 'windspeed',\n",
       "       'log_count', 'rainyday', 'ideal', 'sticky', 'peak', 'temp(difference)',\n",
       "       'discomfort_index', 'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_5',\n",
       "       'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12',\n",
       "       'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18',\n",
       "       'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'hw_0', 'hw_1',\n",
       "       'hw_2', 'hw_3', 'hw_5', 'hw_6', 'hw_7', 'hw_8', 'hw_9', 'hw_10',\n",
       "       'hw_11', 'hw_12', 'hw_13', 'hw_14', 'hw_15', 'hw_16', 'hw_17', 'hw_18',\n",
       "       'hw_19', 'hw_20', 'hw_21', 'hw_22', 'hw_23', 'year_2012', 'dayofweek_0',\n",
       "       'dayofweek_2', 'dayofweek_3', 'dayofweek_4', 'dayofweek_5',\n",
       "       'dayofweek_6', 'season_2', 'season_3', 'season_4', 'month_2', 'month_3',\n",
       "       'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9',\n",
       "       'month_10', 'month_11', 'month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vC6uzhDO8k9o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(rmsle)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSLE 값을 출력하는 함수\n",
    "def rmsle(y,y_,convertExp=True):\n",
    "    # 지수화 필요하다면\n",
    "    if convertExp:\n",
    "        y = np.exp(y),\n",
    "        y_ = np.exp(y_)\n",
    "    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n",
    "    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return np.sqrt(np.mean(calc))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle)\n",
    "rmsle_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L0G1JRdN8k9p"
   },
   "outputs": [],
   "source": [
    "## cross val score를 측정해주는 함수\n",
    "def cv_score(models, n = 5):\n",
    "    # kfold 수는 default인 5로 지정\n",
    "    kf = KFold(n_splits = n, shuffle=True, random_state = 0)\n",
    "    \n",
    "    for model in models:\n",
    "#       model.fit(X_train,y_train)\n",
    "        score =  cross_val_score(model, X_features, target, cv = kf, scoring=rmsle_scorer)\n",
    "        print(model[0],'의 평균 score:', round(score.mean(), 5))\n",
    "        print(model[0],'의 std:', round(score.std(), 5))\n",
    "        print()      \n",
    "        \n",
    "        # y_valid과 prediction을 비교하여 시각화 해주는 코드\n",
    "#        g = sns.kdeplot(np.exp(y_valid),  color = 'skyblue', alpha = .6, fill = True, label = 'valid')\n",
    "#        g = sns.kdeplot(np.exp(model.predict(X_valid)), color = 'orange', alpha = .3, fill = True, label = 'prediction')\n",
    "#       plt.legend()\n",
    "#        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TM6ZMe4N8k9q"
   },
   "outputs": [],
   "source": [
    "## 제출을 위한 함수\n",
    "def submission(model):\n",
    "    model.fit(X_features, target)\n",
    "    prediction = np.exp(model.predict(X_test))\n",
    "    \n",
    "    # 자동으로 형식을 맞춰 csv 생성해주는 코드\n",
    "    submission = pd.DataFrame(test['datetime'])\n",
    "    submission['count'] = prediction\n",
    "\n",
    "    pd.DataFrame(submission).to_csv('submission_bike.csv', index = False)\n",
    "    \n",
    "    return pd.DataFrame(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UnDsz2xr8k9q",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 의 평균 score: 0.33474\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 의 std: 0.00817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "# 기본 모델을 아래와 같이 5가지로 정했음.                                             mean val_score    std\n",
    "pipe_lr = Pipeline([('model', LinearRegression())])                                 #   0.33503     / 0.00783\n",
    "#pipe_rf = Pipeline([('model', RandomForestRegressor(n_estimators=500))])            #   0.4394      / 0.01136 \n",
    "#pipe_lgbm = Pipeline([('model', LGBMRegressor(n_estimators=100))])                  #   0.32172     / 0.0055\n",
    "#pipe_gb = Pipeline([('model', GradientBoostingRegressor())])                        #   0.59616     / 0.01654\n",
    "#pipe_xgb = Pipeline([('model', XGBRegressor(objective ='reg:squarederror'))])       #   0.59705     / 0.0167\n",
    "\n",
    "#models = [pipe_lr, pipe_rf, pipe_lgbm, pipe_gb, pipe_xgb]\n",
    "models = [pipe_lr]\n",
    "# 평균 valid score 측정\n",
    "cv_score(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P7WBB5348k9s",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>12.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>6.137719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>3.402837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>2.304724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>2.543634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-20 05:00:00</td>\n",
       "      <td>9.674865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-01-20 06:00:00</td>\n",
       "      <td>40.653223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-01-20 07:00:00</td>\n",
       "      <td>114.126181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-01-20 08:00:00</td>\n",
       "      <td>185.788583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-01-20 09:00:00</td>\n",
       "      <td>97.046992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011-01-20 10:00:00</td>\n",
       "      <td>50.742195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011-01-20 11:00:00</td>\n",
       "      <td>61.027716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2011-01-20 12:00:00</td>\n",
       "      <td>77.675436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011-01-20 13:00:00</td>\n",
       "      <td>74.845777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2011-01-20 14:00:00</td>\n",
       "      <td>67.749719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011-01-20 15:00:00</td>\n",
       "      <td>73.613477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011-01-20 16:00:00</td>\n",
       "      <td>108.158068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011-01-20 17:00:00</td>\n",
       "      <td>207.667346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011-01-20 18:00:00</td>\n",
       "      <td>177.107663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011-01-20 19:00:00</td>\n",
       "      <td>117.404472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011-01-20 20:00:00</td>\n",
       "      <td>84.977185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011-01-20 21:00:00</td>\n",
       "      <td>63.894070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2011-01-20 22:00:00</td>\n",
       "      <td>46.883052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2011-01-20 23:00:00</td>\n",
       "      <td>29.597660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2011-01-21 00:00:00</td>\n",
       "      <td>13.432219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2011-01-21 01:00:00</td>\n",
       "      <td>6.155727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2011-01-21 02:00:00</td>\n",
       "      <td>2.094381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2011-01-21 03:00:00</td>\n",
       "      <td>1.260420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2011-01-21 04:00:00</td>\n",
       "      <td>2.470194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2011-01-21 05:00:00</td>\n",
       "      <td>9.808047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>2012-12-30 18:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>2012-12-30 19:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>2012-12-30 20:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>2012-12-30 21:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>2012-12-30 22:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>2012-12-30 23:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>2012-12-31 00:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>2012-12-31 01:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>2012-12-31 02:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>2012-12-31 03:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>2012-12-31 04:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>2012-12-31 05:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>2012-12-31 06:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>2012-12-31 07:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>2012-12-31 08:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>2012-12-31 09:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>2012-12-31 10:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>2012-12-31 11:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6481</th>\n",
       "      <td>2012-12-31 12:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>2012-12-31 13:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>2012-12-31 14:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>2012-12-31 15:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>2012-12-31 16:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>2012-12-31 17:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>2012-12-31 18:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>2012-12-31 19:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>2012-12-31 20:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>2012-12-31 21:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>2012-12-31 22:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>2012-12-31 23:00:00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime       count\n",
       "0     2011-01-20 00:00:00   12.447059\n",
       "1     2011-01-20 01:00:00    6.137719\n",
       "2     2011-01-20 02:00:00    3.402837\n",
       "3     2011-01-20 03:00:00    2.304724\n",
       "4     2011-01-20 04:00:00    2.543634\n",
       "5     2011-01-20 05:00:00    9.674865\n",
       "6     2011-01-20 06:00:00   40.653223\n",
       "7     2011-01-20 07:00:00  114.126181\n",
       "8     2011-01-20 08:00:00  185.788583\n",
       "9     2011-01-20 09:00:00   97.046992\n",
       "10    2011-01-20 10:00:00   50.742195\n",
       "11    2011-01-20 11:00:00   61.027716\n",
       "12    2011-01-20 12:00:00   77.675436\n",
       "13    2011-01-20 13:00:00   74.845777\n",
       "14    2011-01-20 14:00:00   67.749719\n",
       "15    2011-01-20 15:00:00   73.613477\n",
       "16    2011-01-20 16:00:00  108.158068\n",
       "17    2011-01-20 17:00:00  207.667346\n",
       "18    2011-01-20 18:00:00  177.107663\n",
       "19    2011-01-20 19:00:00  117.404472\n",
       "20    2011-01-20 20:00:00   84.977185\n",
       "21    2011-01-20 21:00:00   63.894070\n",
       "22    2011-01-20 22:00:00   46.883052\n",
       "23    2011-01-20 23:00:00   29.597660\n",
       "24    2011-01-21 00:00:00   13.432219\n",
       "25    2011-01-21 01:00:00    6.155727\n",
       "26    2011-01-21 02:00:00    2.094381\n",
       "27    2011-01-21 03:00:00    1.260420\n",
       "28    2011-01-21 04:00:00    2.470194\n",
       "29    2011-01-21 05:00:00    9.808047\n",
       "...                   ...         ...\n",
       "6463  2012-12-30 18:00:00         inf\n",
       "6464  2012-12-30 19:00:00         inf\n",
       "6465  2012-12-30 20:00:00         inf\n",
       "6466  2012-12-30 21:00:00         inf\n",
       "6467  2012-12-30 22:00:00         inf\n",
       "6468  2012-12-30 23:00:00         inf\n",
       "6469  2012-12-31 00:00:00         inf\n",
       "6470  2012-12-31 01:00:00         inf\n",
       "6471  2012-12-31 02:00:00         inf\n",
       "6472  2012-12-31 03:00:00         inf\n",
       "6473  2012-12-31 04:00:00         inf\n",
       "6474  2012-12-31 05:00:00         inf\n",
       "6475  2012-12-31 06:00:00         inf\n",
       "6476  2012-12-31 07:00:00         inf\n",
       "6477  2012-12-31 08:00:00         inf\n",
       "6478  2012-12-31 09:00:00         inf\n",
       "6479  2012-12-31 10:00:00         inf\n",
       "6480  2012-12-31 11:00:00         inf\n",
       "6481  2012-12-31 12:00:00         inf\n",
       "6482  2012-12-31 13:00:00         inf\n",
       "6483  2012-12-31 14:00:00         inf\n",
       "6484  2012-12-31 15:00:00         inf\n",
       "6485  2012-12-31 16:00:00         inf\n",
       "6486  2012-12-31 17:00:00         inf\n",
       "6487  2012-12-31 18:00:00         inf\n",
       "6488  2012-12-31 19:00:00         inf\n",
       "6489  2012-12-31 20:00:00         inf\n",
       "6490  2012-12-31 21:00:00         inf\n",
       "6491  2012-12-31 22:00:00         inf\n",
       "6492  2012-12-31 23:00:00         inf\n",
       "\n",
       "[6493 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr 모델 제출 결과 : => inf 값 나와서 실패.. 왜지...\n",
    "# rf 모델 제출 결과 : 0.52784  **\n",
    "# lgbm 모델 제출 결과 : 0.41477  **\n",
    "# gb 모델 제출 결과 : 0.66858\n",
    "# xgb 모델 제출 결과 : 0.52387  **\n",
    "\n",
    "submission(pipe_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37sj2GTY8k9s"
   },
   "source": [
    "[RMSLE 평가 지표에 대해](https://ahnjg.tistory.com/90)\n",
    "\n",
    "요약 \n",
    "1. 큰 것보다 적은 것을 오차없이 예측할 때 점수가 더 좋음.\n",
    "2. under estimator에 대해 페널티를 부과한다. <b> 예측값 > 실제값</b> 보다 <b>예측값 < 실제값</b>일 때, 점수가 안 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1lvpGmu8k9t"
   },
   "source": [
    "## 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRtalzLcVKKq"
   },
   "outputs": [],
   "source": [
    "def search_params(x = X_features, y = target, model, paras, n = 5, scorer = rmsle_scorer) :\n",
    "    # pipeline 으로 받은 모델을 부르고\n",
    "    model = model['model']\n",
    "\n",
    "    # kfold \n",
    "    kf = KFold(n_splits = n, shuffle=True, random_state = 0)\n",
    "\n",
    "    grid_model = GridSearchCV(estimator = model, param_grid = paras, cv=kf, n_jobs=-1, verbose=2, scoring = scorer)\n",
    "    grid_model.fit(x,y)\n",
    "    \n",
    "    # grid_search한 결과를 Dataframe화\n",
    "    scores_df = pd.DataFrame(grid_model.cv_results_)\n",
    "    scores_df[['params', 'mean_test_score','rank_test_score', 'split0_test_score', 'split1_test_score','split2_test_score']]\n",
    "    \n",
    "    # GridSearchCV 의 best score는 높은 점수를 알려줌. \n",
    "    # 즉, 현재 우리의 평가지표(rslme)는 낮은 점수일수록 좋은 평가이기 때문에 score를 오름차순으로 정렬해서 확인\n",
    "    scores_df = scores_df.sort_values('mean_test_score', ascending = True).loc[:,['params','mean_test_score']]\n",
    "\n",
    "    return(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0vQTZ1rVqBl"
   },
   "outputs": [],
   "source": [
    "#lgbm에 대한 parameters\n",
    "para_lgbm = [{\n",
    "    'learning_rate' : [0.01, 0.03, 0.05, 0.07, 0.1],\n",
    "    'n_estimators' : [500, 800, 1000, 1300, 1500],\n",
    "    'random_state' : [0]}]\n",
    "    \n",
    "search_params(X_features, target, pipe_lgbm, para_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uQdDraZOqW6"
   },
   "source": [
    "1000/0.03 이 best score인 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUcDtSoH8k9u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lgbm (1500, 0.03, random_state = 0)\n",
    "pipe_lgbm4 = Pipeline([('model', LGBMRegressor(n_estimators=1500, learning_rate = 0.03))])\n",
    "\n",
    "submission(pipe_lgbm4) # 0.399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OswJVHO9Zieh"
   },
   "outputs": [],
   "source": [
    "cv_lgbm5 = Pipeline([('model', LGBMRegressor(n_estimators=1500, learning_rate = 0.03, random_state=0))])\n",
    "model5 = [cv_lgbm5]\n",
    "cv_score(model5)     \n",
    "\n",
    "#   파라미터 조정 후         파라미터 조정 전\n",
    "# 0.28621  / 0.00548   =>    0.32172  / 0.0055"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXAFx9M1aW9v"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO85Od3JX_Fl"
   },
   "source": [
    "### *참고 ) 헤매는동안 살펴본 값들*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-4--XJGN3fW"
   },
   "outputs": [],
   "source": [
    "# grid_lgbm2 = LGBMRegressor()\n",
    "# #\n",
    "# kf = KFold(n_splits = 5, shuffle=True, random_state = 0)\n",
    "\n",
    "# grid_lgbm2 = GridSearchCV(estimator = grid_lgbm2, param_grid = para_lgbm, cv=kf, n_jobs=-1, verbose=2, scoring = rmsle_scorer)\n",
    "# grid_lgbm2.fit(X_features, target)\n",
    "\n",
    "# #lgbm \n",
    "# print(\"lgbm best param is : \", grid_lgbm2.best_params_)\n",
    "# print(\"lgbm best score is : \", grid_lgbm2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdWY0mRB8k9u"
   },
   "outputs": [],
   "source": [
    "# pipe_lgbm2 = Pipeline([('model', LGBMRegressor(n_estimators=500, learning_rate = 0.01, random_state = 0))])\n",
    "\n",
    "# submission(pipe_lgbm2) # 0.46298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuNHOUgO8k9v"
   },
   "outputs": [],
   "source": [
    "# pipe_lgbm3 = Pipeline([('model', LGBMRegressor(n_estimators=1000, learning_rate = 0.05, random_state = 0))])\n",
    "# submission(pipe_lgbm3)  # 0.39642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDdIZ0pKHJPh"
   },
   "outputs": [],
   "source": [
    "# pipe_lgbm4 = Pipeline([('model', LGBMRegressor(n_estimators=1000, learning_rate = 0.07, random_state = 0))])\n",
    "# submission(pipe_lgbm4)   # 0.404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsCce9NQC4zF"
   },
   "outputs": [],
   "source": [
    "# cv_lgbm = Pipeline([('model', LGBMRegressor(n_estimators=500, learning_rate = 0.01))])\n",
    "# model1 = [cv_lgbm]\n",
    "# cv_score(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrnQtngsDsWh"
   },
   "outputs": [],
   "source": [
    "# cv_lgbm2 = Pipeline([('model', LGBMRegressor(n_estimators=1000, learning_rate = 0.05, random_state=0))])\n",
    "# model2 = [cv_lgbm2]\n",
    "# cv_score(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zl2TxzEIJgKW"
   },
   "outputs": [],
   "source": [
    "# cv_lgbm3 = Pipeline([('model', LGBMRegressor(n_estimators=1000, learning_rate = 0.07, random_state=0))])\n",
    "# model3 = [cv_lgbm3]\n",
    "# cv_score(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hya-6G7EH34H"
   },
   "outputs": [],
   "source": [
    "# scores_df.sort_values('mean_test_score', ascending = True).loc[:,['params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V0NBT1GakVA"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsP5ZRk8antW"
   },
   "source": [
    "## 앞으로 찾아야할 파라미터값들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4-HY_Sm8k9v"
   },
   "outputs": [],
   "source": [
    "para_xgb = [{\n",
    "    'eta' : [0.01, 0.05, 0.1, 0.15, 0.2], \n",
    "    'gamma' : [0, 0.3, 0.5],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'random_state' : [0],\n",
    "    'objective' : ['reg:squarederror']}]\n",
    "\n",
    "grid_xgb = XGBRegressor()\n",
    "\n",
    "\n",
    "xgb_para = GridSearchCV(estimator = grid_xgb, param_grid = para_xgb, cv=10, n_jobs=-1, verbose=2, scoring = rmsle_scorer)\n",
    "xgb_para.fit(X_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URxcHbit8k9v"
   },
   "outputs": [],
   "source": [
    "print(\"xgb best param is : \", xgb_para.best_params_)\n",
    "print(\"xgb best score is : \", xgb_para.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6coGii8r8k9v"
   },
   "outputs": [],
   "source": [
    "pipe_xgb2 = Pipeline([('model', XGBRegressor(eta = 0.01, gamma= 0.3, max_depth= 4, objective= 'reg:squarederror', random_state= 0))])\n",
    "submission(pipe_xgb2)  # 1.7656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AMNe_o-atwJ"
   },
   "outputs": [],
   "source": [
    "#rf에 대한 parameters\n",
    "para_rf = [{\n",
    "    'max_depth' : [6, 8, 10, 12, 14],\n",
    "    'n_estimators' : [100,200,300,400,500],\n",
    "    'min_samples_split' : [2, 5, 7,10],\n",
    "    'min_samples_leaf' : [1, 2, 4],\n",
    "    'random_state' : [0]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MouTmhFM8k9w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "가영,호섭님 모델 참고.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
